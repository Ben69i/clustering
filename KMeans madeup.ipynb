{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0020c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import classification_report \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fff4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX,dataY,dataCenter=make_blobs(n_samples=200,\n",
    "                                  n_features=2,\n",
    "                                  return_centers=True,\n",
    "                                  centers=3,\n",
    "                                  random_state=42,\n",
    "                                  cluster_std=3.3\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats_basic import skew\n",
    "skew(dataX)\n",
    "#skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0cee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.set()\n",
    "plt.scatter(dataX[:,0],dataX[:,1],c=dataY,cmap=\"viridis_r\")\n",
    "plt.scatter(dataCenter[:,0],dataCenter[:,1],c=\"red\",s=55)\n",
    "plt.title(\"RawData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3884969",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=KMeans(random_state=106,n_clusters=3,init=\"k-means++\",max_iter=100,verbose=1,algorithm=\"lloyd\")\n",
    "kk.fit(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataX[:,0],dataX[:,1],c=kk.labels_,cmap=\"viridis_r\")\n",
    "plt.scatter(kk.cluster_centers_[:,0],kk.cluster_centers_[:,1],c=\"Red\",s=65)\n",
    "plt.title(\"Sklearn Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6ab24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import random\n",
    "#random.seed(42)\n",
    "\n",
    "class KMeansAlgorithms:\n",
    "    def __init__(self, k=3, max_iterations=100, use_elkan=False, use_lloyd=True):\n",
    "        self.k = k #\n",
    "        self.max_iterations = max_iterations\n",
    "        self.use_elkan = use_elkan \n",
    "        self.use_lloyd = use_lloyd \n",
    "        \n",
    "    # Initialize centroids using KMeans++\n",
    "    def initialize_centroids(self, X): #Kmeans++\n",
    "        centroids = []\n",
    "        centroid_idx = random.choice(range(X.shape[0]))\n",
    "        centroids.append(X[centroid_idx]) \n",
    "        \n",
    "        distances = np.zeros((X.shape[0],))\n",
    "        remaining_points = set(range(X.shape[0]))\n",
    "        \n",
    "        for _ in range(self.k - 1):\n",
    "            for idx in remaining_points:\n",
    "                distances[idx] = min([distance.euclidean(X[idx], c) for c in centroids])\n",
    "\n",
    "            probabilities = distances / sum(distances) \n",
    "            next_centroid_idx = np.random.choice(range(X.shape[0]), p=probabilities) \n",
    "            centroids.append(X[next_centroid_idx])\n",
    "            remaining_points.remove(next_centroid_idx)\n",
    "\n",
    "        return np.array(centroids)\n",
    "    \n",
    "    # Assign each point to its closest cluster center\n",
    "    def assign_clusters(self, X, centroids):\n",
    "        clusters = np.zeros((X.shape[0],), dtype=np.int32)\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            closest_centroid_index = np.argmin([distance.euclidean(X[i], c) for c in centroids])\n",
    "            clusters[i] = closest_centroid_index\n",
    "        \n",
    "        return clusters\n",
    "     \n",
    "    # Update centroids based on assigned clusters\n",
    "    def update_centroids(self, X, clusters):\n",
    "        updated_centroids = np.zeros((self.k, X.shape[1]))\n",
    "        counts = np.zeros((self.k, ))\n",
    "\n",
    "        for idx, label in enumerate(clusters):\n",
    "            updated_centroids[label] += X[idx]\n",
    "            counts[label] += 1\n",
    "            \n",
    "        for i in range(updated_centroids.shape[0]):\n",
    "            updated_centroids[i] /= counts[i]\n",
    "        \n",
    "        return updated_centroids\n",
    "      \n",
    "    # --->Elkan algorithm<---\n",
    "    def update_centroids_elkan(self, X, clusters, old_centroids):\n",
    "        updated_centroids = np.copy(old_centroids)\n",
    "        changes = False\n",
    "\n",
    "        for j in range(self.k):\n",
    "            neighbor_list = list(set(range(X.shape[0])) - set(clusters[clusters != j]))\n",
    "            \n",
    "            squared_distances = np.zeros((len(neighbor_list)))\n",
    "            \n",
    "            for i, neighbor in enumerate(neighbor_list):\n",
    "\n",
    "                sqr_dist = distance.squareform(distance.pdist([X[neighbor], updated_centroids[j]], 'euclidean'))\n",
    "                lowerbound = max([sqr_dist[0][1] + sqr_dist[1][0] - distance.squareform(distance.pdist(old_centroids[[j]]))[0][0]])\n",
    "                upperbound = sqr_dist[0][0]\n",
    "                bounds = (lowerbound <= upperbound) | ((upperbound - lowerbound) < 1e-10)\n",
    "                squared_distances[i] = upperbound if bounds else float('inf')\n",
    "             \n",
    "            if len(squared_distances) > 0:\n",
    "                min_index = np.argmin(squared_distances)\n",
    "                updated_centroids[j] = X[neighbor_list[min_index]]\n",
    "                changes = True\n",
    "            else:\n",
    "                updates_needed = True\n",
    "                while updates_needed:\n",
    "                    updates_needed = False\n",
    "                    neighbors = np.where(clusters == j)[0]\n",
    "                    non_empty_dimensions = np.count_nonzero(~np.isnan(X[neighbors].sum(axis=0)), axis=-1)\n",
    "                    dimensions_to_drop = np.argsort(non_empty_dimensions)[::-1][self.k:]\n",
    "                    if len(dimensions_to_drop) > 0:\n",
    "                        drop_indices = np.ix_(dimensions_to_drop, range(X.shape[1]))\n",
    "                        dropped_data = np.delete(X[neighbors], dimensions_to_drop, axis=1)\n",
    "                        \n",
    "                        mean_dropped_data = np.mean(dropped_data, axis=0)\n",
    "                        indices = np.arange(len(neighbors)).reshape(-1, 1)[:, np.newaxis]\n",
    "                        means = np.repeat(mean_dropped_data[np.newaxis, :], repeats=len(neighbors), axis=0)\n",
    "                        differences = X[neighbors][indices, drop_indices] - means[indices, drop_indices]\n",
    "                        \n",
    "                        squares = np.power(differences, 2)\n",
    "                        variances = np.sum(squares, axis=1)/(len(neighbors)-1)\n",
    "                        threshold = np.percentile(variances, 100-(100/(len(neighbors)+1)))\n",
    "                        \n",
    "                        selected_dimensions = np.where(variances > threshold)[0]\n",
    "                        selected_dimensions = np.concatenate([selected_dimensions, dimensions_to_drop]).tolist()\n",
    "                        X[neighbors] = X[neighbors][..., selected_dimensions]\n",
    "                        \n",
    "                        updated_centroids[j] = np.mean(X[neighbors], axis=0)\n",
    "                        if len(selected_dimensions) < X.shape[1]:\n",
    "                            updates_needed = True\n",
    "                            changes = True\n",
    "                        elif np.linalg.norm(updated_centroids[j] - old_centroids[j]) > 1e-10:\n",
    "                            changes = True\n",
    "                        else:\n",
    "                            break\n",
    "        \n",
    "        return updated_centroids if changes else old_centroids\n",
    "\n",
    "    # --->Fitting Function<---\n",
    "    def fit(self, X):\n",
    "        centroids = self.initialize_centroids(X)\n",
    "        previous_centroids = None\n",
    "        iteration = 0\n",
    "\n",
    "        if self.use_elkan:\n",
    "            fitting_func = self._fit_elkan\n",
    "        elif self.use_lloyd:\n",
    "            fitting_func = self._fit_lloyd\n",
    "        else:\n",
    "            raise ValueError(\"Please select valid fitting method.\")\n",
    "\n",
    "        while True:\n",
    "            iteration += 1 \n",
    "            clusters = self.assign_clusters(X, centroids)\n",
    "            old_centroids = centroids\n",
    "            centroids = fitting_func(X, clusters, old_centroids)\n",
    "            \n",
    "            if np.allclose(old_centroids, centroids):\n",
    "                break\n",
    "            \n",
    "            if iteration >= self.max_iterations:\n",
    "                break\n",
    "          \n",
    "        return centroids, clusters\n",
    "\n",
    "    def _fit_elkan(self, X, clusters, old_centroids):\n",
    "        centroids = self.update_centroids_elkan(X, clusters, old_centroids)\n",
    "        return centroids\n",
    "\n",
    "    def _fit_lloyd(self, X, clusters, old_centroids):\n",
    "        centroids = self.update_centroids(X, clusters)\n",
    "        return centroids\n",
    "\n",
    "# Usage Example\n",
    "    \"\"\"kmeans = KMeansAlgorithms(k=3, max_iterations=100, use_elkan=True, use_lloyd=False)\n",
    "    centroids, clusters = kmeans.fit(X)\n",
    "    print(\"Centroids:\", centroids)\n",
    "    print(\"Clusters:\", clusters)\n",
    "    kmeans = KMeansAlgorithms(k=3, max_iterations=100, use_elkan=False, use_lloyd=True)\n",
    "    centroids, clusters = kmeans.fit(X)\n",
    "    print(\"Centroids:\", centroids)\n",
    "    print(\"Clusters:\", clusters)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmaCent,kmalabel=KMeansAlgorithms(k=3,max_iterations=100,use_elkan=False,use_lloyd=True).fit(dataX)\n",
    "kmaCent2,kmalabel2=KMeansAlgorithms(k=3,max_iterations=100,use_elkan=True,use_lloyd=False).fit(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1,2,figsize=(11,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(dataX[:,0],dataX[:,1],c=kmalabel,cmap=\"viridis_r\")\n",
    "plt.scatter(kmaCent[:,0],kmaCent[:,1],c=\"Red\",s=65)\n",
    "plt.title(\"lloyd pred\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(dataX[:,0],dataX[:,1],c=kmalabel2,cmap=\"viridis_r\")\n",
    "plt.scatter(kmaCent2[:,0],kmaCent2[:,1],c=\"Red\",s=65)\n",
    "plt.title(\"Elkan pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ccf9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KMeans Sklearn\n",
    "confusion_matrix(dataY,kk.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dac141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#made-up kmeans elkan algo\n",
    "confusion_matrix(dataY,kmalabel2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#made-up kmeans lloyd algo\n",
    "confusion_matrix(dataY,kmalabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0749997",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Statistics for Sklearn:\\n{classification_report(dataY,kk.labels_)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53029622",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk_params={\"init\":[\"k-means++\",\"random\"],#2 \n",
    "           \"copy_x\":[True,False],#2 \n",
    "           \"tol\":[1e-5,1e-4,1e-3,1e-2,1e-2,0.1],#6 \n",
    "           \"algorithm\":[\"lloyd\",\"elkan\"],#2 \n",
    "          \"max_iter\":[50,100,200,300]#4\n",
    "          }\n",
    "kkgrd=GridSearchCV(estimator=KMeans(n_clusters=3,random_state=42),param_grid=kk_params)\n",
    "kkgrd.fit(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kkgrd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dd5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(dataY,KMeans(n_clusters=3,max_iter=50,copy_x=True,init=\"random\",\n",
    "                              tol=0.1,algorithm=\"lloyd\",random_state=42).fit_predict(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88d195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#madeup-lloyd:6\n",
    "#sklearn-lloyd:11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778ce283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start=time.perf_counter_ns()\n",
    "kk=KMeans(random_state=106,n_clusters=3,init=\"k-means++\",max_iter=100,algorithm=\"lloyd\")\n",
    "print(f\"{time.perf_counter_ns()-start:,} ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfcd563",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.perf_counter_ns()\n",
    "kk2=KMeansAlgorithms(k=3,max_iterations=100,use_elkan=False,use_lloyd=True)\n",
    "print(f\"{time.perf_counter_ns()-start:,} ns\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
